{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import re\n",
    "\n",
    "import rosbag\n",
    "import geometry_msgs.msg as geomsg\n",
    "\n",
    "import cameratransform as ct\n",
    "from tf.transformations import quaternion_from_euler, euler_from_quaternion\n",
    "from scipy.spatial.transform import Rotation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from cv_bridge import CvBridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = rosbag.Bag(\"../record.bag\")\n",
    "model_topic = \"/gazebo/model_states\"\n",
    "camera_topic = \"/robot/camera_rgb_00\"\n",
    "event_topic = \"/robot/camera_dvs_00/events\"\n",
    "bridge = CvBridge()\n",
    "g = postprocess.process_bag(bag, bridge, model_topic, camera_topic, event_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = pathlib.Path(\"../Models/\")\n",
    "dae_models = models_path.glob(\"*/*.dae\")\n",
    "meshes = {key.stem: postprocess.get_mesh(key) for key in dae_models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_poses = postprocess.camera_pose_generator(bag, model_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = postprocess.camera_transform_generator(camera_poses, 0.5003983220157445 * 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (t, c) in camera:\n",
    "    image = np.zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagfile = \"../record.bag\"\n",
    "bagfolder = pathlib.Path(\"../record.bag\")\n",
    "bag = rosbag.Bag(bagfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_topic = '/gazebo/model_states'\n",
    "camera_topic = '/robot/camera_rgb_00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic, msg, t in bag.read_messages(topics=['/robot/camera_dvs_00/events']):\n",
    "    print(dir(msg))\n",
    "    coordinates = []\n",
    "    for event in msg.events:\n",
    "        coo = np.array([event.x, event.y, 1 if event.polarity else 0])\n",
    "        coordinates.append(coo)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge = CvBridge()\n",
    "count = 0\n",
    "timestamp = 0\n",
    "for topic, msg, t in bag.read_messages(topics=[camera_topic]):\n",
    "    if count <37:\n",
    "        count += 1\n",
    "        continue\n",
    "    timestamp = t\n",
    "    image = bridge.imgmsg_to_cv2(msg, \"bgr8\")\n",
    "    plt.imshow(image)\n",
    "    msg.data = None\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### count = 0\n",
    "hammer_pose = None\n",
    "for topic, msg, t in bag.read_messages(topics=[model_topic]):\n",
    "    #if len(msg.pose) > 1:\n",
    "    print(msg)\n",
    "    if t >= timestamp and t.to_nsec() < 229716000000:\n",
    "        hammer_pose = msg.pose[1]\n",
    "        camera_pose = msg.pose[0]\n",
    "        print(camera_pose)\n",
    "        print(hammer_pose)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = pathlib.Path('../Models')\n",
    "hammer_file = models_path / 'hammer_simple' / 'hammer_simple.dae'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(hammer_file) as fp:\n",
    "    xml = fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = \"hammer_simple\"\n",
    "\n",
    "all_vertices_meshes = {shape: np.zeros((0, 3), dtype=float)}\n",
    "all_triangles_meshes = {shape: np.zeros((0, 3), dtype=int)}\n",
    "all_physical_scales = {shape: None}\n",
    "\n",
    "vertices_info = re.findall(r'<float_array.+?mesh-positions-array.+?>(.+?)</float_array>', xml)\n",
    "transform_info = re.findall(r'<matrix sid=\"transform\">(.+?)</matrix>.+?<instance_geometry', xml, flags=re.DOTALL)  # better way?\n",
    "triangles_info = re.findall(r'<triangles.+?<p>(.+?)</p>.+?</triangles>', xml, flags=re.DOTALL)\n",
    "if len(triangles_info) == 0:\n",
    "    triangles_info = re.findall(r'<polylist.+?<p>(.+?)</p>.+?</polylist>', xml, flags=re.DOTALL)\n",
    "for part_id in range(len(vertices_info)):\n",
    "    transform_matrix = np.array([float(n) for n in transform_info[part_id].split(' ')]).reshape((4, 4))\n",
    "    vertices_temp = np.array([float(n) for n in vertices_info[part_id].split(' ')])\n",
    "    vertices_temp = np.reshape(vertices_temp, (int(vertices_temp.shape[0]/3), 3))\n",
    "    vertices_temp = np.dot(transform_matrix, np.c_[vertices_temp, np.ones(vertices_temp.shape[0])].T)[:-1].T\n",
    "    triangles_temp = np.array([int(n) for n in triangles_info[part_id].split(' ')])[::3]\n",
    "    triangles_temp = np.reshape(triangles_temp, (int(triangles_temp.shape[0]/3), 3))\n",
    "    triangles_temp = triangles_temp + all_vertices_meshes[shape].shape[0]  # shift triangle indices\n",
    "    all_vertices_meshes[shape] = np.vstack((all_vertices_meshes[shape], vertices_temp))\n",
    "    all_triangles_meshes[shape] = np.vstack((all_triangles_meshes[shape], triangles_temp))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientation = hammer_pose.orientation\n",
    "orientation_quat = np.array([orientation.x, orientation.y, orientation.z, orientation.w])\n",
    "rotation = Rotation.from_quat(orientation_quat)\n",
    "#rotation = Rotation.from_euler('z', hammer_pose.orientation.z)\n",
    "position = np.array([hammer_pose.position.x, hammer_pose.position.y, hammer_pose.position.z])\n",
    "shape_mesh = all_vertices_meshes[shape]\n",
    "hammer_meshes = position + rotation.apply(shape_mesh)\n",
    "\n",
    "hammer_meshes, position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geomsg.Pose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_from_position(camera_pose, resolution=(512, 512), focal_length=0.5003983220157445*512):\n",
    "    orientation = camera_pose.orientation\n",
    "    roll, pitch, yaw = euler_from_quaternion([orientation.x, orientation.y, orientation.z, orientation.w])\n",
    "    (roll, pitch, yaw) = (angle_in_rad*180/np.pi for angle_in_rad in (roll, pitch, yaw))\n",
    "    \n",
    "    position = camera_pose.position\n",
    "    camera_projection = ct.RectilinearProjection(focallength_px=focal_length, image=(512, 512))\n",
    "    camera_orientation = ct.SpatialOrientation(pos_x_m=position.x, pos_y_m=position.y, elevation_m=position.z,\n",
    "                    roll_deg=roll, tilt_deg=90-pitch, heading_deg=90-yaw)\n",
    "    #camera_lens = ct.BrownLensDistortion(k1=0.0, k2=0.0, k3=0.0, projection=camera_projection)\n",
    "    transformation = ct.Camera(projection=camera_projection, orientation=camera_orientation)#, lens=camera_lens)\n",
    "    return transformation\n",
    "\n",
    "dummy_pose = geomsg.Pose()\n",
    "dummy_pose.position.x = 1\n",
    "dummy_pose.position.y = 0.03\n",
    "dummy_pose.position.z = 1\n",
    "dummy_pose.orientation.z = -0.9773382675958592\n",
    "dummy_pose.orientation.w = 0.21168351540147112\n",
    "#camera = camera_from_position(dummy_pose)\n",
    "#camera_pose.position.x = 0\n",
    "camera_pose.position.y = 0.02\n",
    "camera_pose.position.z = 1\n",
    "camera = camera_from_position(camera_pose)\n",
    "projected_mesh = camera.imageFromSpace(hammer_meshes)\n",
    "triangle_mesh = np.take(projected_mesh, all_triangles_meshes['hammer_simple'], axis=0).astype(int)\n",
    "\n",
    "distance_layer = np.zeros((512, 512, 3))\n",
    "for mesh in triangle_mesh:\n",
    "    cv2.fillConvexPoly(distance_layer, mesh, (1, 1, 1))\n",
    "overlay = distance_layer + ( image / 300)\n",
    "plt.imshow(overlay)\n",
    "distance_layer.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances_to_cam(camera, vertices, distance_threshold = 0.1):\n",
    "        camera_vector = np.array([camera.pos_x_m, camera.pos_y_m, camera.elevation_m])\n",
    "        #cam_vector = np.array([l-p for (p,l) in zip(cam_pos, self.camera_look_at)])\n",
    "        distances = vertices - camera_vector\n",
    "        proj_dist = np.dot(camera_vector/np.linalg.norm(camera_vector), distances.T)\n",
    "        norm_dist = np.linalg.norm(distances, axis=1)\n",
    "        norm_dist[proj_dist < distance_threshold] = np.nan\n",
    "        return norm_dist\n",
    "distances = compute_distances_to_cam(camera, all_triangles_meshes['hammer_simple']).reshape(-1, 1).repeat(3, axis=1)\n",
    "distances /= distances.max()\n",
    "distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_layer = np.zeros((512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(map(lambda x: [x[0], -x[1]], triangle_mesh[0])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
