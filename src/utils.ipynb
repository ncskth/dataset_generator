{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import pathlib\n",
    "import re\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import rosbag\n",
    "import geometry_msgs.msg as geomsg\n",
    "import message_filters\n",
    "\n",
    "import cameratransform as ct\n",
    "from tf.transformations import quaternion_from_euler, euler_from_quaternion\n",
    "from scipy.spatial.transform import Rotation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from cv_bridge import CvBridge\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import av\n",
    "import postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GazeboRosPkgs\t\t     data\t\t\t       rb\r\n",
      "Models\t\t\t     events.npz\t\t\t       record.bag\r\n",
      "NRPExp_DVSDatabaseGenerator  events.pt\t\t\t       rosbag2video.py\r\n",
      "README.md\t\t     gazebo_actor-updaterate_patch.sh  setup.sh\r\n",
      "Scripts_deprecated\t     logs.zip\t\t\t       src\r\n",
      "Untitled.ipynb\t\t     nrp_installer.sh\r\n"
     ]
    }
   ],
   "source": [
    "!ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = rosbag.Bag(\"../record.bag\")\n",
    "#model_topic = \"/gazebo/model_states\"\n",
    "model_topic = \"/gazebo_modelstates_with_timestamp\"\n",
    "camera_topic = \"/robot/camera_rgb_00\"\n",
    "event_topic = \"/robot/camera_dvs_00/events\"\n",
    "bridge = CvBridge()\n",
    "g = postprocess.process_bag(bag, bridge, model_topic, camera_topic, event_topic, model_path=\"../Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic, msg, t in bag.read_messages(topics=[event_topic]):\n",
    "#    d = {n: i for i, n in enumerate(msg.name)}\n",
    "#     i = d[\"animated camera::eye_vision_camera\"]\n",
    "    #msg.events = None\n",
    "    #print(msg)\n",
    "    for event in msg.events:\n",
    "        print(event.x, event.y, int(not event.polarity))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_poses = postprocess.camera_pose_generator(bag, model_topic)\n",
    "images = postprocess.image_generator(bag, bridge, camera_topic)\n",
    "events = postprocess.event_generator(bag, event_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['hammer_simple', 'table', 'flathead_screwdriver', 'adjustable_spanner', 'eric_handR', 'eric_calfR', 'eric_head', 'eric_legL', 'eric', 'eric_footL', 'eric_forearmR', 'eric_calfL', 'eric_armL', 'eric_torso', 'eric_handL', 'eric_forearmL', 'eric_armR', 'eric_footR', 'eric_legR'])\n"
     ]
    }
   ],
   "source": [
    "for (x, y, z) in g:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hammer = postprocess.get_tool_poses(bag, model_topic)['hammer_simple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dae_models = pathlib.Path(\"../Models\").glob(\"*/*.dae\")\n",
    "meshes = {key.stem: postprocess.get_mesh(key) for key in dae_models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "hammer_mesh = meshes['hammer_simple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = postprocess.transform_tool(hammer_mesh[0], hammer).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientation = hammer.orientation\n",
    "orientation_quat = np.array(\n",
    "    [orientation.x, orientation.y, orientation.z, orientation.w]\n",
    ")\n",
    "rotation = Rotation.from_quat(orientation_quat)\n",
    "r = rotation.as_rotvec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "hammer_pose = np.append(p, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12432555,  2.49447955,  2.        ])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera.getPos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = camera.imageFromSpace(hammer_pose[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344.8329150087951"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.865113249658216"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(hammer_pose[:3] - camera.getPos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'orientation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_451/381098155.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpostprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_tool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhammer_mesh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhammer_pose\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/src/postprocess.py\u001b[0m in \u001b[0;36mtransform_tool\u001b[0;34m(mesh, pose)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mtransform_tool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0morientation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     orientation_quat = np.array(\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'orientation'"
     ]
    }
   ],
   "source": [
    "postprocess.transform_tool(hammer_mesh[0], np.append(np.mean(out, axis=0), hammer_pose[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.69359212e-17, -1.96774603e-18])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hammer_pca = PCA(n_components=2)\n",
    "out = hammer_pca.fit_transform(hammer_mesh[0])\n",
    "np.mean(out, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00624988,  0.00218813,  0.01914704])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(hammer_mesh[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00624988,  0.00218813,  0.01914704])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hammer_pca.inverse_transform(np.mean(out, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = next(camera_poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12432555,  2.49447955,  2.        ])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera = postprocess.transform_camera(pose[1], 0.5003983220157445 * 640, [640, 480])\n",
    "\n",
    "camera.getPos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "position: \n",
       "  x: 0.255637\n",
       "  y: -1.16531\n",
       "  z: 0.78\n",
       "orientation: \n",
       "  x: 0.0\n",
       "  y: 0.0\n",
       "  z: -0.2839618166356312\n",
       "  w: 0.9588355889791493"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = postprocess.align_generators(camera_poses, images, events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "generator raised StopIteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/data/src/postprocess.py\u001b[0m in \u001b[0;36malign_generators\u001b[0;34m(key_fn, value_fn, *generators)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mnew_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mnew_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_451/927064025.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mga\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: generator raised StopIteration"
     ]
    }
   ],
   "source": [
    "for x in ga:\n",
    "    print(list(x))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_labels(camera, tool_poses, tool_meshes):\n",
    "    images = []\n",
    "    for tool_class, (tool, pose) in enumerate(tool_poses.items()):\n",
    "        raw_vertices, raw_triangles = tool_meshes[tool]\n",
    "        transformed = transform_tool(raw_vertices, pose)\n",
    "        projection = camera.imageFromSpace(transformed)\n",
    "        triangles = np.take(projection, raw_triangles, axis=0).astype(int)\n",
    "        image_class = np.zeros((512, 512))\n",
    "        for mesh in triangles:\n",
    "            cv2.fillConvexPoly(image_class, mesh, tool_class + 1)\n",
    "        images.append(image_class)\n",
    "    return np.stack(images, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_tool(mesh, pose):\n",
    "    orientation = pose.orientation\n",
    "    orientation_quat = np.array(\n",
    "        [orientation.x, orientation.y, orientation.z, orientation.w]\n",
    "    )\n",
    "    rotation = Rotation.from_quat(orientation_quat)\n",
    "    rotation_corrected = rotation.as_euler('xyz')\n",
    "    rotation = Rotation.from_euler('xyz', rotation_corrected)\n",
    "    position = np.array([pose.position.x, pose.position.y, pose.position.z])\n",
    "    return position + rotation.apply(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_transform_generator(pose, focal_length=0.5003983220157445 * 512):\n",
    "    for t, (x, y, z, roll, pitch, yaw) in camera_pose_generator:\n",
    "        (roll, pitch, yaw) = (radians / 180 * np.pi for radians in (roll, pitch, yaw))\n",
    "        projection = ct.RectilinearProjection(\n",
    "            focallength_px=focal_length, image=(512, 512)\n",
    "        )\n",
    "        orientation = ct.SpatialOrientation(\n",
    "            pos_x_m=x,\n",
    "            pos_y_m=y,\n",
    "            elevation_m=z,\n",
    "            roll_deg=roll, # TODO: Specify\n",
    "            tilt_deg=90 - pitch,\n",
    "            heading_deg=90 - yaw,\n",
    "        )\n",
    "        yield t, ct.Camera(projection, orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in range(10):\n",
    "out = next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25158657, -1.1600714 ,  0.79914704,  0.        ,  0.        ,\n",
       "        -0.575847  ],\n",
       "       [ 0.18828049, -1.00602331,  0.78000057,  0.        ,  0.        ,\n",
       "         0.195003  ],\n",
       "       [-0.21581907,  0.02921923,  0.77999997,  0.        ,  0.        ,\n",
       "         2.70135   ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 8, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_451/3451808474.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera_pose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_poses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_meshes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpitch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myaw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcamera_pose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mroll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpitch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myaw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mradians\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m180\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mradians\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mroll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpitch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myaw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m projection = ct.RectilinearProjection(\n\u001b[1;32m      5\u001b[0m    \u001b[0mfocallength_px\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5003983220157445\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 8, got 4)"
     ]
    }
   ],
   "source": [
    "(image, camera, camera_pose, tool_poses, tool_meshes, labels, event, times) = out\n",
    "(x, y, z, roll, pitch, yaw) = camera_pose\n",
    "(roll, pitch, yaw) = (radians * 180 / np.pi for radians in (roll, pitch, yaw))\n",
    "projection = ct.RectilinearProjection(\n",
    "   focallength_px=0.5003983220157445 * 512, image=(512, 512)\n",
    ")\n",
    "orientation = ct.SpatialOrientation(\n",
    "   pos_x_m=x, pos_y_m=y, elevation_m=z,\n",
    "   roll_deg=roll, tilt_deg=90-pitch, heading_deg=90-yaw,\n",
    ")\n",
    "camera2 = ct.Camera(projection, orientation)\n",
    "label = image_labels(camera2, tool_poses, tool_meshes)\n",
    "print(camera.getPos())\n",
    "print(times)\n",
    "#plt.imshow(image)\n",
    "#plt.imshow(image / 400  + labels)\n",
    "plt.imshow(event / 400  + labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "(image, events, labels) = out\n",
    "#images = image_labels(camera, tool_poses, tool_meshes)\n",
    "#cl = images[0] + images[1] + images[2]\n",
    "#cl = np.broadcast_to(np.expand_dims(cl, 2), (512, 512, 3))\n",
    "plt.imshow(events / 400 + labels / 4)\n",
    "#plt.imshow(labels)\n",
    "plt.show()\n",
    "cl.min(), cl.max(), cl.mean(), times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[4])x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr =np.array([0, 0.78, 0.78]) - r.as_euler('xyz')\n",
    "Rotation.from_euler('xyz', rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, camera_pose, tool_poses, tool_meshes, times in g:\n",
    "    (x, y, z, roll, pitch, yaw) = camera_pose\n",
    "    (roll, pitch, yaw) = (radians * 180 / np.pi for radians in (roll, pitch, yaw))\n",
    "    projection = ct.RectilinearProjection(\n",
    "        focallength_px=0.5003983220157445 * 512, image=(512, 512)\n",
    "    )\n",
    "    orientation = ct.SpatialOrientation(\n",
    "        pos_x_m=x + 0.04, pos_y_m=y - 0.08, elevation_m=z + 1.0,\n",
    "        roll_deg=roll+11, tilt_deg=90-pitch, heading_deg=90-yaw,\n",
    "    )\n",
    "    camera = ct.Camera(projection, orientation)\n",
    "    print(x, y, z, roll, pitch, yaw, camera_pose[3:])\n",
    "\n",
    "    images = image_labels(camera, tool_poses, tool_meshes)\n",
    "    cl = images[0] + images[1] + images[2]\n",
    "    cl = np.broadcast_to(np.expand_dims(cl, 2), (512, 512, 3))\n",
    "    plt.imshow(image / 300 + cl)\n",
    "    plt.show()\n",
    "    cl.min(), cl.max(), cl.mean(), times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "images = []\n",
    "events = []\n",
    "labels = []\n",
    "for rgb, camera, camera_pose, poses, meshes, label, event, (tc, ti, te) in tqdm.tqdm(g):\n",
    "    images.append(torch.tensor(rgb))\n",
    "    events.append(torch.tensor(event))\n",
    "    labels.append(torch.tensor(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "images = []\n",
    "events = []\n",
    "labels = []\n",
    "for rgb, event, label in tqdm.tqdm(g):\n",
    "    images.append(torch.tensor(rgb))\n",
    "    events.append(torch.tensor(event))\n",
    "    labels.append(torch.tensor(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(events[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_images = torch.stack([torch.tensor(x) for x in images])\n",
    "torch_events = torch.stack([torch.tensor(x) for x in events])\n",
    "torch_labels = torch.stack([torch.tensor(x) for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.io.write_video(\"e.mp4\", torch_events / 3 + torch_labels * 100, fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "\n",
    "dataset = \"../data/datasetdvs_2021-06-16-19-23-07\"\n",
    "files = !ls $dataset\n",
    "sorted_files = natsorted(files)\n",
    "len(sorted_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "file_images = []\n",
    "file_labels = []\n",
    "for file in tqdm.tqdm(sorted_files):\n",
    "    with np.load(f\"{dataset}/{file}\") as data:\n",
    "        rgb = data['images'] / 300\n",
    "        label = data['labels']\n",
    "        file_images.append(rgb)\n",
    "        file_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(file_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "plt.imshow(labels[i].sum(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = torch.stack([torch.tensor(x) for x in images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.io.write_video(\"h.mp4\", ims, fps=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
